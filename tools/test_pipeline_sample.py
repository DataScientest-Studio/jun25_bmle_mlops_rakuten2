#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Script de test rapide du pipeline sur un √©chantillon r√©duit AVEC PROFILING D√âTAILL√â.
====================================================================================

Ce script permet de v√©rifier que tout fonctionne correctement
en lan√ßant le pipeline complet sur un petit √©chantillon de donn√©es,
et affiche un profiling d√©taill√© de chaque √©tape de transformation.

Utilisation:
    python tools/test_pipeline_sample.py --sample-size 2000  # Taille de l'√©chantillon
    python tools/test_pipeline_sample.py # Utilise la taille par d√©faut (1000)
    python tools/test_pipeline_sample.py --with-cv  # Active la validation crois√©e
    python tools/test_pipeline_sample.py --profile-features  # Profiling d√©taill√© des features
    # Profiling rapide (√©chantillon plus petit pour le profiling)
    python tools/test_pipeline_sample.py --sample-size 2000 --profile-features --profile-sample-size 300
    # Test complet avec tous les d√©tails
    python tools/test_pipeline_sample.py --sample-size 2000 --profile-features --verbose

"""
import sys
import logging
import argparse
from pathlib import Path

# Ajouter le r√©pertoire parent au PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.utils.logging_config import setup_logging
from src.utils.config import load_config
from src.pipeline_steps.stage01_data_ingestion import DataIngestionPipeline
from src.pipeline_steps.stage02_data_validation import DataValidationPipeline
from src.pipeline_steps.stage03_data_transformation import DataTransformationPipeline
from src.pipeline_steps.stage04_model_training import ModelTrainingPipeline
from src.pipeline_steps.stage05_model_evaluation import ModelEvaluationPipeline
from src.utils.profiling import Timer

# Import du profiler de features
try:
    from src.utils.feature_profiler import profile_pipeline
    PROFILER_AVAILABLE = True
except ImportError:
    PROFILER_AVAILABLE = False
    logging.warning("  Feature profiler non disponible (src.utils.feature_profiler)")

logger = logging.getLogger(__name__)


def parse_args():
    """Parse les arguments de ligne de commande."""
    parser = argparse.ArgumentParser(
        description="Test rapide du pipeline sur un √©chantillon"
    )
    
    parser.add_argument(
        "--sample-size",
        type=int,
        default=1000,
        help="Taille de l'√©chantillon (d√©faut: 1000)"
    )
    
    parser.add_argument(
        "--config",
        type=str,
        default="config/config.toml",
        help="Chemin vers le fichier de configuration"
    )
    
    parser.add_argument(
        "--with-cv",
        action="store_true",
        help="Activer la validation crois√©e"
    )
    
    parser.add_argument(
        "--skip-validation",
        action="store_true",
        help="Ignorer la validation des donn√©es"
    )
    
    parser.add_argument(
        "--profile-features",
        action="store_true",
        help="Activer le profiling d√©taill√© des transformateurs de features"
    )
    
    parser.add_argument(
        "--profile-sample-size",
        type=int,
        default=500,
        help="Taille de l'√©chantillon pour le profiling (d√©faut: 500, plus rapide)"
    )
    
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Mode verbeux"
    )
    
    return parser.parse_args()


def profile_feature_pipeline(feature_pipeline, X_sample, y_sample, config):
    """
    Profile le pipeline de features en d√©tail.
    
    Args:
        feature_pipeline: Pipeline de features √† profiler
        X_sample: √âchantillon de donn√©es X
        y_sample: √âchantillon de labels y
        config: Configuration du projet
    """
    if not PROFILER_AVAILABLE:
        logger.warning("  Profiling ignor√© : feature_profiler non disponible")
        return
    
    logger.info("\n" + "=" * 70)
    logger.info(" PROFILING D√âTAILL√â DES FEATURES")
    logger.info("=" * 70)
    logger.info(f" √âchantillon de profiling : {len(X_sample)} lignes")
    logger.info(f" Cela peut prendre quelques minutes...\n")
    
    try:
        # Profiler le pipeline complet
        results = profile_pipeline(
            pipeline=feature_pipeline,
            X=X_sample,
            y=y_sample,
            max_depth=3
        )
        
        # Afficher le r√©sum√©
        results.print_summary()
        
        # Identifier les goulots d'√©tranglement
        bottlenecks = results.get_bottlenecks(top_n=5)
        
        logger.info("\n" + "=" * 70)
        logger.info(" RECOMMANDATIONS D'OPTIMISATION")
        logger.info("=" * 70)
        
        total_transform = sum(p.transform_time for p in results.profiles)
        
        for i, bottleneck in enumerate(bottlenecks[:3], 1):
            pct = (bottleneck.transform_time / total_transform * 100) if total_transform > 0 else 0
            logger.info(f"\n{i}. {bottleneck.name}")
            logger.info(f"   ‚è±  Temps: {bottleneck.transform_time:.2f}s ({pct:.1f}% du total)")
            logger.info(f"    M√©moire: {bottleneck.memory_mb:.1f} MB")
            logger.info(f"    Shape: {bottleneck.output_shape}")
            logger.info(f"    D√©bit: {bottleneck.samples_per_sec:.0f} samples/sec")
            
            # Suggestions d'optimisation
            if 'tfidf' in bottleneck.name.lower() or 'countvectorizer' in bottleneck.name.lower():
                logger.info("    Suggestion: R√©duire max_features ou augmenter min_df")
            elif 'svd' in bottleneck.name.lower() or 'pca' in bottleneck.name.lower():
                logger.info("    Suggestion: R√©duire n_components")
            elif bottleneck.memory_mb > 1000:
                logger.info("    Suggestion: Consid√©rer une repr√©sentation sparse ou r√©duire la dimensionnalit√©")
        
        logger.info("\n" + "=" * 70 + "\n")
        
        # Sauvegarder les r√©sultats d√©taill√©s
        import json
        from pathlib import Path
        
        output_dir = Path("artifacts/profiling")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        output_file = output_dir / "feature_profiling_results.json"
        with open(output_file, 'w') as f:
            json.dump(results.to_dict(), f, indent=2)
        
        logger.info(f" R√©sultats d√©taill√©s sauvegard√©s : {output_file}")
        
    except Exception as e:
        logger.error(f" Erreur durant le profiling : {e}")
        import traceback
        traceback.print_exc()


def main():
    """Fonction principale."""
    args = parse_args()
    
    # Configuration du logging
    log_level = logging.DEBUG if args.verbose else logging.INFO
    setup_logging(level=log_level)
    
    # En-t√™te
    logger.info("\n" + "=" * 70)
    logger.info(" TEST RAPIDE DU PIPELINE RAKUTEN")
    logger.info("=" * 70)
    logger.info(f" √âchantillon: {args.sample_size} lignes")
    logger.info(f"  Config: {args.config}")
    if args.profile_features:
        logger.info(f" Profiling: ACTIV√â ({args.profile_sample_size} lignes)")
    logger.info("=" * 70 + "\n")
    
    try:
        # ========================================
        # Chargement de la configuration
        # ========================================
        config = load_config(args.config)
        logger.info(f" Configuration charg√©e")
        logger.info(f"   Mod√®le: {config.model['name'].upper()}")
        logger.info(f"   Random seed: {config.random_seed}")
        
        # Override CV si demand√©
        if args.with_cv:
            config.cv['enabled'] = True
            logger.info(f"   Validation crois√©e: ACTIV√âE (--with-cv)")
        
        with Timer("Test pipeline complet"):
            
            # ========================================
            # √âTAPE 1 : Data Ingestion
            # ========================================
            logger.info("\n" + "üîπ" * 35)
            logger.info(" √âTAPE 1/5 : INGESTION (√©chantillon)")
            
            stage1 = DataIngestionPipeline(config)
            X_train, y_train, X_test = stage1.run()
            
            # üî¨ √âCHANTILLONNAGE
            logger.info(f"\n √âchantillonnage √† {args.sample_size} lignes...")
            sample_size_train = min(args.sample_size, len(X_train))
            sample_size_test = min(args.sample_size // 5, X_test.shape[0])  # 20% pour test
            
            X_train = X_train.sample(n=sample_size_train, random_state=42)
            y_train = y_train.loc[X_train.index]
            X_test = X_test.sample(n=sample_size_test, random_state=42)
            
            logger.info(f" √âchantillon train: {len(X_train)} lignes")
            logger.info(f" √âchantillon test: {X_test.shape[0]} lignes")
            
            # ========================================
            # √âTAPE 2 : Data Validation
            # ========================================
            if not args.skip_validation:
                logger.info("\n" + "üîπ" * 35)
                logger.info(" √âTAPE 2/5 : VALIDATION")
                
                stage2 = DataValidationPipeline(config)
                validation_ok = stage2.run(X_train, y_train, X_test)
                
                if not validation_ok:
                    logger.error("\n Validation √©chou√©e")
                    return 1
            else:
                logger.warning("\n  Validation ignor√©e")
            
            # ========================================
            # √âTAPE 3 : Data Transformation
            # ========================================
            logger.info("\n" + "üîπ" * 35)
            logger.info(" √âTAPE 3/5 : TRANSFORMATION")
            
            stage3 = DataTransformationPipeline(config)
            X_train_t, y_train_t, X_test_t, feature_pipeline, feature_mapping = stage3.run(
                X_train, y_train, X_test
            )
            
            logger.info(f" Features: {X_train_t.shape[1]} colonnes")
            
            # ========================================
            # PROFILING D√âTAILL√â (optionnel)
            # ========================================
            if args.profile_features:
                # Cr√©er un sous-√©chantillon pour le profiling
                profile_size = min(args.profile_sample_size, len(X_train))
                X_profile = X_train.sample(n=profile_size, random_state=42)
                y_profile = y_train.loc[X_profile.index]
                
                logger.info(f"\nüîç Lancement du profiling sur {profile_size} lignes...")
                profile_feature_pipeline(feature_pipeline, X_profile, y_profile, config)
            
            # ========================================
            # √âTAPE 4 : Model Training
            # ========================================
            logger.info("\n" + "üîπ" * 35)
            logger.info(" √âTAPE 4/5 : ENTRA√éNEMENT")
            
            stage4 = ModelTrainingPipeline(config)
            model = stage4.run(X_train_t, y_train_t, feature_pipeline)
            
            # ========================================
            # √âTAPE 5 : Model Evaluation
            # ========================================
            logger.info("\n" + "üîπ" * 35)
            logger.info(" √âTAPE 5/5 : √âVALUATION")
            
            stage5 = ModelEvaluationPipeline(config)
            
            # √âvaluation sur train
            logger.info(f"\n √âvaluation sur train ({X_train_t.shape[0]} √©chantillons)...")
            train_results = stage5.run(
                model, X_train_t, y_train_t,
                dataset_name="train_sample",
                trainer=stage4.trainer
            )
            
            # Pr√©dictions sur test
            logger.info(f"\n Pr√©dictions sur test ({X_test_t.shape[0]} √©chantillons)...")
            test_results = stage5.run(
                model, X_test_t, y_true=None,
                dataset_name="test_sample",
                trainer=stage4.trainer
            )
            
            # ========================================
            # R√âSUM√â FINAL
            # ========================================
            logger.info("\n" + "=" * 70)
            logger.info(" TEST TERMIN√â AVEC SUCC√àS !")
            logger.info("=" * 70)
            logger.info(f" √âchantillon train: {len(X_train)} ‚Üí {X_train_t.shape[0]} lignes")
            logger.info(f" √âchantillon test: {X_test.shape[0]} ‚Üí {X_test_t.shape[0]} lignes")
            logger.info(f" Features: {X_train_t.shape[1]} colonnes")
            logger.info(f" Mod√®le: {config.model['name'].upper()}")
            
            if 'accuracy' in train_results:
                logger.info(f" Accuracy (train): {train_results['accuracy']:.4f}")
                logger.info(f" F1 (train): {train_results['f1_weighted']:.4f}")
            
            logger.info(f" Pr√©dictions: {len(test_results['predictions'])} g√©n√©r√©es")
            
            if args.profile_features:
                logger.info(f" Profiling: R√©sultats sauvegard√©s dans artifacts/profiling/")
            
            logger.info("=" * 70)
            
            logger.info("\n TOUS LES TESTS PASSENT !")
            logger.info(" Le pipeline fonctionne correctement.")
            logger.info(" Ok pour lancer sur les donn√©es compl√®tes.\n")
            
            return 0
            
    except FileNotFoundError as e:
        logger.error(f"\n Erreur: Fichier non trouv√©: {e}")
        logger.error(" V√©rification que les fichiers CSV existent dans data/raw/")
        return 1
        
    except Exception as e:
        logger.error(f"\n Erreur durant le test: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())